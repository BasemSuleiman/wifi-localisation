{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from utils.misc import *\n",
    "from utils.classifier import *\n",
    "from utils.visualiser import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "df_train = pd.read_csv(\"../data/train/df_train.csv\", index_col=0)\n",
    "\n",
    "df_train_b0 = pd.read_csv(\"../data/train/df_train_b0.csv\", index_col=0)\n",
    "df_train_b1 = pd.read_csv(\"../data/train/df_train_b1.csv\", index_col=0)\n",
    "df_train_b2 = pd.read_csv(\"../data/train/df_train_b2.csv\", index_col=0)\n",
    "\n",
    "df_train_b0_f0 = pd.read_csv(\"../data/train/df_train_b0_f0.csv\", index_col=0)\n",
    "df_train_b0_f1 = pd.read_csv(\"../data/train/df_train_b0_f1.csv\", index_col=0)\n",
    "df_train_b0_f2 = pd.read_csv(\"../data/train/df_train_b0_f2.csv\", index_col=0)\n",
    "df_train_b0_f3 = pd.read_csv(\"../data/train/df_train_b0_f3.csv\", index_col=0)\n",
    "\n",
    "df_train_b1_f0 = pd.read_csv(\"../data/train/df_train_b1_f0.csv\", index_col=0)\n",
    "df_train_b1_f1 = pd.read_csv(\"../data/train/df_train_b1_f1.csv\", index_col=0)\n",
    "df_train_b1_f2 = pd.read_csv(\"../data/train/df_train_b1_f2.csv\", index_col=0)\n",
    "df_train_b1_f3 = pd.read_csv(\"../data/train/df_train_b1_f3.csv\", index_col=0)\n",
    "\n",
    "df_train_b2_f0 = pd.read_csv(\"../data/train/df_train_b2_f0.csv\", index_col=0)\n",
    "df_train_b2_f1 = pd.read_csv(\"../data/train/df_train_b2_f1.csv\", index_col=0)\n",
    "df_train_b2_f2 = pd.read_csv(\"../data/train/df_train_b2_f2.csv\", index_col=0)\n",
    "df_train_b2_f3 = pd.read_csv(\"../data/train/df_train_b2_f3.csv\", index_col=0)\n",
    "df_train_b2_f4 = pd.read_csv(\"../data/train/df_train_b2_f4.csv\", index_col=0)\n",
    "\n",
    "df_train_wap = np.load(\"../data/train/df_train_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_train_b0_wap = np.load(\"../data/train/df_train_b0_wap.npy\", allow_pickle=True)\n",
    "df_train_b1_wap = np.load(\"../data/train/df_train_b1_wap.npy\", allow_pickle=True)\n",
    "df_train_b2_wap = np.load(\"../data/train/df_train_b2_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_train_b0_f0_wap = np.load(\"../data/train/df_train_b0_f0_wap.npy\", allow_pickle=True)\n",
    "df_train_b0_f1_wap = np.load(\"../data/train/df_train_b0_f1_wap.npy\", allow_pickle=True)\n",
    "df_train_b0_f2_wap = np.load(\"../data/train/df_train_b0_f2_wap.npy\", allow_pickle=True)\n",
    "df_train_b0_f3_wap = np.load(\"../data/train/df_train_b0_f3_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_train_b1_f0_wap = np.load(\"../data/train/df_train_b1_f0_wap.npy\", allow_pickle=True)\n",
    "df_train_b1_f1_wap = np.load(\"../data/train/df_train_b1_f1_wap.npy\", allow_pickle=True)\n",
    "df_train_b1_f2_wap = np.load(\"../data/train/df_train_b1_f2_wap.npy\", allow_pickle=True)\n",
    "df_train_b1_f3_wap = np.load(\"../data/train/df_train_b1_f3_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_train_b2_f0_wap = np.load(\"../data/train/df_train_b2_f0_wap.npy\", allow_pickle=True)\n",
    "df_train_b2_f1_wap = np.load(\"../data/train/df_train_b2_f1_wap.npy\", allow_pickle=True)\n",
    "df_train_b2_f2_wap = np.load(\"../data/train/df_train_b2_f2_wap.npy\", allow_pickle=True)\n",
    "df_train_b2_f3_wap = np.load(\"../data/train/df_train_b2_f3_wap.npy\", allow_pickle=True)\n",
    "df_train_b2_f4_wap = np.load(\"../data/train/df_train_b2_f4_wap.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "df_test = pd.read_csv(\"../data/test/df_test.csv\", index_col=0)\n",
    "\n",
    "df_test_b0 = pd.read_csv(\"../data/test/df_test_b0.csv\", index_col=0)\n",
    "df_test_b1 = pd.read_csv(\"../data/test/df_test_b1.csv\", index_col=0)\n",
    "df_test_b2 = pd.read_csv(\"../data/test/df_test_b2.csv\", index_col=0)\n",
    "\n",
    "df_test_b0_f0 = pd.read_csv(\"../data/test/df_test_b0_f0.csv\", index_col=0)\n",
    "df_test_b0_f1 = pd.read_csv(\"../data/test/df_test_b0_f1.csv\", index_col=0)\n",
    "df_test_b0_f2 = pd.read_csv(\"../data/test/df_test_b0_f2.csv\", index_col=0)\n",
    "df_test_b0_f3 = pd.read_csv(\"../data/test/df_test_b0_f3.csv\", index_col=0)\n",
    "\n",
    "df_test_b1_f0 = pd.read_csv(\"../data/test/df_test_b1_f0.csv\", index_col=0)\n",
    "df_test_b1_f1 = pd.read_csv(\"../data/test/df_test_b1_f1.csv\", index_col=0)\n",
    "df_test_b1_f2 = pd.read_csv(\"../data/test/df_test_b1_f2.csv\", index_col=0)\n",
    "df_test_b1_f3 = pd.read_csv(\"../data/test/df_test_b1_f3.csv\", index_col=0)\n",
    "\n",
    "df_test_b2_f0 = pd.read_csv(\"../data/test/df_test_b2_f0.csv\", index_col=0)\n",
    "df_test_b2_f1 = pd.read_csv(\"../data/test/df_test_b2_f1.csv\", index_col=0)\n",
    "df_test_b2_f2 = pd.read_csv(\"../data/test/df_test_b2_f2.csv\", index_col=0)\n",
    "df_test_b2_f3 = pd.read_csv(\"../data/test/df_test_b2_f3.csv\", index_col=0)\n",
    "df_test_b2_f4 = pd.read_csv(\"../data/test/df_test_b2_f4.csv\", index_col=0)\n",
    "\n",
    "df_test_wap = np.load(\"../data/test/df_test_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_test_b0_wap = np.load(\"../data/test/df_test_b0_wap.npy\", allow_pickle=True)\n",
    "df_test_b1_wap = np.load(\"../data/test/df_test_b1_wap.npy\", allow_pickle=True)\n",
    "df_test_b2_wap = np.load(\"../data/test/df_test_b2_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_test_b0_f0_wap = np.load(\"../data/test/df_test_b0_f0_wap.npy\", allow_pickle=True)\n",
    "df_test_b0_f1_wap = np.load(\"../data/test/df_test_b0_f1_wap.npy\", allow_pickle=True)\n",
    "df_test_b0_f2_wap = np.load(\"../data/test/df_test_b0_f2_wap.npy\", allow_pickle=True)\n",
    "df_test_b0_f3_wap = np.load(\"../data/test/df_test_b0_f3_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_test_b1_f0_wap = np.load(\"../data/test/df_test_b1_f0_wap.npy\", allow_pickle=True)\n",
    "df_test_b1_f1_wap = np.load(\"../data/test/df_test_b1_f1_wap.npy\", allow_pickle=True)\n",
    "df_test_b1_f2_wap = np.load(\"../data/test/df_test_b1_f2_wap.npy\", allow_pickle=True)\n",
    "df_test_b1_f3_wap = np.load(\"../data/test/df_test_b1_f3_wap.npy\", allow_pickle=True)\n",
    "\n",
    "df_test_b2_f0_wap = np.load(\"../data/test/df_test_b2_f0_wap.npy\", allow_pickle=True)\n",
    "df_test_b2_f1_wap = np.load(\"../data/test/df_test_b2_f1_wap.npy\", allow_pickle=True)\n",
    "df_test_b2_f2_wap = np.load(\"../data/test/df_test_b2_f2_wap.npy\", allow_pickle=True)\n",
    "df_test_b2_f3_wap = np.load(\"../data/test/df_test_b2_f3_wap.npy\", allow_pickle=True)\n",
    "df_test_b2_f4_wap = np.load(\"../data/test/df_test_b2_f4_wap.npy\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exclusive WAPs in each floor\n",
    "\n",
    "How many WAPs are exclusive to each floor? If every floor has a large number of distinct WAPs, we can just use the presence of RSSI to estimate floors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING 0\n",
      "Total number of WAPs in use in floor 0:  119\n",
      "Total number of WAPs in use in floor 1:  133\n",
      "Total number of WAPs in use in floor 2:  168\n",
      "Total number of WAPs in use in floor 3:  162\n"
     ]
    }
   ],
   "source": [
    "print(\"BUILDING 0\")\n",
    "print(\"Total number of WAPs in use in floor 0: \",  \n",
    "      df_train_b0_f0.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 1: \",  \n",
    "      df_train_b0_f1.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 2: \",  \n",
    "      df_train_b0_f2.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 3: \",  \n",
    "      df_train_b0_f3.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLOOR\n",
       "0     7\n",
       "1     1\n",
       "2    18\n",
       "3    21\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert RSSI vectors into dummy variables\n",
    "df_b0_wap_bool = df_train_b0.iloc[:, :465].astype(bool)\n",
    "floor = df_train_b0['FLOOR']\n",
    "df_b0_wap_floor = pd.concat([df_b0_wap_bool, floor], axis=1)\n",
    "\n",
    "# The occurrence of WAPs in each floor\n",
    "df_b0_wap_floor = df_b0_wap_floor.groupby('FLOOR').sum().astype(bool)\n",
    "\n",
    "# WAPs only in one floor\n",
    "exclusive_waps = np.where(df_b0_wap_floor.sum(axis=0) == 1)\n",
    "\n",
    "# count how many unique WAPs in one floor\n",
    "df_b0_wap_floor[df_b0_wap_floor.columns[exclusive_waps]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING 1\n",
      "Total number of WAPs in use in floor 0:  121\n",
      "Total number of WAPs in use in floor 1:  168\n",
      "Total number of WAPs in use in floor 2:  190\n",
      "Total number of WAPs in use in floor 3:  146\n"
     ]
    }
   ],
   "source": [
    "print(\"BUILDING 1\")\n",
    "print(\"Total number of WAPs in use in floor 0: \",  \n",
    "      df_train_b1_f0.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 1: \",  \n",
    "      df_train_b1_f1.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 2: \",  \n",
    "      df_train_b1_f2.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 3: \",  \n",
    "      df_train_b1_f3.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLOOR\n",
       "0     1\n",
       "1     8\n",
       "2    22\n",
       "3     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b1_wap_bool = df_train_b1.iloc[:, :465].astype(bool)\n",
    "floor = df_train_b1['FLOOR']\n",
    "df_b1_wap_floor = pd.concat([df_b1_wap_bool, floor], axis=1)\n",
    "\n",
    "df_b1_wap_floor = df_b1_wap_floor.groupby('FLOOR').sum().astype(bool)\n",
    "exclusive_waps = np.where(df_b1_wap_floor.sum(axis=0) == 1)\n",
    "df_b1_wap_floor[df_b1_wap_floor.columns[exclusive_waps]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BUILDING 2\n",
      "Total number of WAPs in use in floor 0:  88\n",
      "Total number of WAPs in use in floor 1:  161\n",
      "Total number of WAPs in use in floor 2:  149\n",
      "Total number of WAPs in use in floor 3:  178\n",
      "Total number of WAPs in use in floor 4:  119\n"
     ]
    }
   ],
   "source": [
    "print(\"BUILDING 2\")\n",
    "print(\"Total number of WAPs in use in floor 0: \",  \n",
    "      df_train_b2_f0.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 1: \",  \n",
    "      df_train_b2_f1.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 2: \",  \n",
    "      df_train_b2_f2.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 3: \",  \n",
    "      df_train_b2_f3.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())\n",
    "print(\"Total number of WAPs in use in floor 4: \",  \n",
    "      df_train_b2_f4.iloc[:, :465].astype(bool).sum(axis=0).astype(bool).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FLOOR\n",
       "0     1\n",
       "1    11\n",
       "2     6\n",
       "3    18\n",
       "4     4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_b2_wap_bool = df_train_b2.iloc[:, :465].astype(bool)\n",
    "floor = df_train_b2['FLOOR']\n",
    "df_b2_wap_floor = pd.concat([df_b2_wap_bool, floor], axis=1)\n",
    "\n",
    "df_b2_wap_floor = df_b2_wap_floor.groupby('FLOOR').sum().astype(bool)\n",
    "exclusive_waps = np.where(df_b2_wap_floor.sum(axis=0) == 1)\n",
    "df_b2_wap_floor[df_b2_wap_floor.columns[exclusive_waps]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RESULT - KNN\n",
      "Average balanced accuracy: 98.17% ± 0.87%\n",
      "Average balanced accuracy: 97.20% ± 2.76%\n",
      "Average balanced accuracy: 96.30% ± 2.01%\n"
     ]
    }
   ],
   "source": [
    "print(\"CV RESULT - KNN\")\n",
    "cvs = classification(df_train_b0, df_train_b0_wap, 'floor', 'knn')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b1, df_train_b1_wap, 'floor', 'knn')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b2, df_train_b2_wap, 'floor', 'knn')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RESULT - MULTI-LR\n",
      "Average balanced accuracy: 98.71% ± 0.76%\n",
      "Average balanced accuracy: 97.81% ± 2.81%\n",
      "Average balanced accuracy: 98.51% ± 0.96%\n"
     ]
    }
   ],
   "source": [
    "print(\"CV RESULT - MULTI-LR\")\n",
    "cvs = classification(df_train_b0, df_train_b0_wap, 'floor', 'lr')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b1, df_train_b1_wap, 'floor', 'lr')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b2, df_train_b2_wap, 'floor', 'lr')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV RESULT - SVM\n",
      "Average balanced accuracy: 98.91% ± 0.73%\n",
      "Average balanced accuracy: 97.82% ± 2.91%\n",
      "Average balanced accuracy: 98.88% ± 0.73%\n"
     ]
    }
   ],
   "source": [
    "print(\"CV RESULT - SVM\")\n",
    "cvs = classification(df_train_b0, df_train_b0_wap, 'floor', 'svm')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b1, df_train_b1_wap, 'floor', 'svm')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "cvs = classification(df_train_b2, df_train_b2_wap, 'floor', 'svm')\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter tuning & model evaluation using SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.05}\n",
      "Average balanced accuracy: 98.93% ± 0.69%\n",
      "Test accuracy: 93.44%\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'data'      : df_train_b0,\n",
    "    'wap'       : df_train_b0_wap,\n",
    "    'target'    : 'floor',\n",
    "    'classifier': 'svm'\n",
    "}\n",
    "\n",
    "best_estimator, cvs = tune_parameter(**kwargs)\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "\n",
    "pred = best_estimator.predict(df_test_b0_wap)\n",
    "print(\"Test accuracy: %.2f%%\" % (balanced_accuracy_score(df_test_b0['FLOOR'], pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1}\n",
      "Average balanced accuracy: 97.67% ± 3.09%\n",
      "Test accuracy: 88.56%\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'data'      : df_train_b1,\n",
    "    'wap'       : df_train_b1_wap,\n",
    "    'target'    : 'floor',\n",
    "    'classifier': 'svm'\n",
    "}\n",
    "\n",
    "best_estimator, cvs = tune_parameter(**kwargs)\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "\n",
    "pred = best_estimator.predict(df_test_b1_wap)\n",
    "print(\"Test accuracy: %.2f%%\" % (balanced_accuracy_score(df_test_b1['FLOOR'], pred) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST PARAMS: {'C': 0.1}\n",
      "Average balanced accuracy: 98.90% ± 0.69%\n",
      "Test accuracy: 91.00%\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    'data'      : df_train_b2,\n",
    "    'wap'       : df_train_b2_wap,\n",
    "    'target'    : 'floor',\n",
    "    'classifier': 'svm'\n",
    "}\n",
    "\n",
    "best_estimator, cvs = tune_parameter(**kwargs)\n",
    "print(\"Average balanced accuracy: %.2f%% ± %.2f%%\" % (mean_ci(cvs)[0]* 100, mean_ci(cvs)[1] * 100))\n",
    "\n",
    "pred = best_estimator.predict(df_test_b2_wap)\n",
    "print(\"Test accuracy: %.2f%%\" % (balanced_accuracy_score(df_test_b2['FLOOR'], pred) * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('venv': virtualenv)",
   "language": "python",
   "name": "python38064bitvenvvirtualenve617f17e49084a7c973a4e86cf48a722"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
